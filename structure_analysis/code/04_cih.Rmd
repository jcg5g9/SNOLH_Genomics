---
title: "Analysis 2 - Phase 4: Hybridization between Neosho Bass, Ouachita Bass, and Little River Bass"
author: "Joe Gunn"
date: "2022-08-13"
output: html_document
---

# Project: Central Interior Highlands Hybridization: Spotted, Smallmouth, Neosho, Ouachita, and Little River Bass (SNOLH)
<font size="+1">Investigating hybridization and population structure among and within the black basses (genus Micropterus) in the Central Interior Highlands (CIH) ecoregion, including natural and anthropogenic hybridization between Spotted Bass (SPB; <i>Micropterus punctulatus</i>) and species within the Smallmouth Bass species complex (SMBC): Smallmouth Bass (SMB; <i>M. dolomieu</i>), the newly elevated Neosho Bass (NB; <i>M. velox</i>), and two other potentially distinct species in the Ouachita River Basin, the Ouachita Bass (OB; <i>M. cf. dolomieu </i> Ouachita River), and the Little River Bass (LRB; <i>M. cf. dolomieu </i> Little River).</font>

## Specific Aim: Hierarchical structure and hybrid detection in Smallmouth Bass and Central Interior Highlands Species
For this aim, we are using Bayesian inference with STRUCTURE and NEWHYBRIDS to assess patterns and levels of hybridization among species in the CIH, including NB, OB, and LRB.

### Libraries needed for analysis
```{r}
library(tidyverse)
library(cowplot)
library(readxl)
library(writexl)
library(genepopedit)
library(pophelper)
library(parallelnewhybrid)
library(forcats)
```

### STEP 1: Data preparation

#### 1a: Load in full raw dataset ('full_data'), metadata ('metadata'), and genotype data ('genotype_data')

##### 1a.1: Run the Rmd chunk below to load in all data.

##### Load data:
```{r}
load("../../filtering_analysis/data/processed_raw_data/full_data.rda")
load("../data/filtering_data/spb_smbc_hybrids.rda")
load("../data/filtering_data/smb_cih_hybrids.rda")
```

#### 1b: Filter metadata and SNP genotype data 
In this step, we are filtering the metadata and SNP genotype data to only include samples of interest for analysis of population structure and hybridization among species in the CIH. For this analysis, these data will include NB, OB, and LRB, but only SNP loci that were found to be diagnostic between NB and all other CIH species (CIH-SNPS)

##### 1b.1. Filter metadata; run the Rmd chunk below:

##### Filter metadata to only include CIH species (excluding SPB and SMB)
```{r}
## get metadata for c-binding later
cih_metadata <- full_data[1:13]

## Filter out SPB and SMB from the metadata
cih_metadata <- cih_metadata %>%
  filter(Putative_Taxon != "SPB") %>%
  filter(Putative_Taxon != "SMB") 

# Remove hybrids detected with SPB (Analysis 2, Step 1b (1b_spb_other.Rmd))
cih_metadata <- cih_metadata[ ! cih_metadata$Structure_Num %in% spb_smbc_hybrids, ] 

# Remove hybrids detected with SMB (Analysis 2, Step 1c (1c_smb_ih.Rmd))
cih_metadata <- cih_metadata[ ! cih_metadata$Structure_Num %in% smb_cih_hybrids, ]

## Convert factors to characters
cih_metadata <- cih_metadata %>%
  mutate(Structure_Num = as.character(Structure_Num),
         River = as.character(River))
```

##### 1b.2. Filter SNP genotype data; run the Rmd chunk below:

##### Filter out genotype data into diagnostic SNP groups for NB, OB, and LRB
```{r}
## Filter out SPB and SMB from genotype data
cih_snps <- full_data %>%
  filter(Putative_Taxon != "SPB") %>%
  filter(Putative_Taxon != "SMB")

# Remove hybrids detected with SPB 
cih_snps <- cih_snps[ ! cih_snps$Structure_Num %in% spb_smbc_hybrids, ]

# Remove hybrids detected with SMB
cih_snps <- cih_snps[ ! cih_snps$Structure_Num %in% smb_cih_hybrids, ]

# Get only SMB diagnostic SNP loci (NEO, OUOU, OULR)
cih_snps <- cih_snps %>%
  dplyr::select(matches("NEO"),
         matches("OUOU"),
         matches("OULR"))
```

<b>Details on CIH only dataset:</b> <br>
<i>N</i><sub>samples</sub> = 396 <br>
<i>N</i><sub>loci</sub> = 138 <br>

#### 1c: Combine metadata and snp datasets for combinations of interest (see above); Run the Rmd chunk below to combine datasets.

##### Combine metadata and snp datasets and generate excel/Rda files: files are stored in the directory `data/processed_genotype_data/`
```{r}
# All Cih species only:
cih <- cbind(cih_metadata, cih_snps)

## Generate excel files to hold genotype data and to prepare:
write_xlsx(cih, path = "../data/processed_genotype_data/cih.xlsx")
```

#### 1d: Generate STRUCTURE formatted files from genepop format
In this step, we are reading in, checking, and converting genepop files for combined datasets into STRUCTURE formatted files. There are quite a few tricky and very specific formatting needs for the genepop text file before genepopedit will convert successfully. Follow Step 3a below closely to create a proper genepop format. Use Ctrl + F to find and replace the necessary things.

##### IMPORTANT NOTE ON DATA: genepopedit requires that sample names be in the format 'popname_01', 'popname_02', etc. where the 'popname' is a signifier for the population of origin for the sample, and the '01', etc. are numerical designations for the samples. 'popname' and the numeric must be separated by a "_", and there can only be a single "_". Otherwise, genepopedit will not read the sample's population of origin correctly. In the case of this project, we are clumping samples together by stream for STRUCTURE analysis to see if there may be substructure mapped by stream. Many sample IDs in our dataset were not in the required format, so we added an additional column to the metadata set and associated processed data sets called "structure_ID", which gives a unique sample name in the proper structure format. This column can then be linked back to any other column in downstream analyses if we need to know which specific samples the results came from.

##### 1d.1. Follow the guide for the library 'genepopedit' (Stanley et al. [year]) to prepare genepop files before converting them to STRUCTURE format.

###### 1d.1.1 All "," in the genepop text files were manually replaced with " ,  "

###### 1d.1.2. All "tabs" between six-digit alleles were were manually replaced with " " (a single space).

###### 1d.1.3. The top row designating the dataset combination was manually omitted.

###### 1d.1.4. Any additional space at the bottom of the text file was removed.

##### 1d.2. Generate STRUCTURE files from genepop files
Here it is important to not include the 'popgroup = ' unless it is explicitly necessary. Assigning popgroup to a dataframe with population names will cause the STRUCTURE input file to have word strings in the popdata column. Our experience is that STRUCTURE expects an integer here rather than a string, so best not to use popgroup.

##### Convert genepop to STRUCTURE format: files are stored in the directory `data/structure_data/`
```{r}
# Generate structure file for CIH Bass only, excluding SMB
genepop_structure("../data/genepop_data/cih_genepop.txt", 
                  locusnames = TRUE, 
                  #popgroup = "data/genepop_data/cih_pops.csv",
                  path = "../data/structure_data/input_data/cih_structure.txt")
```

<b>Details on CIH populations:</b> <br>
<i>N</i><sub>populations</sub> = 18

#### 1e: Generate batch list files and shell scripts for running STRUCTURE in parallel
In this step, we are creating batch lists of command line code to run STRUCTURE analyses in parallel. We are making a single batch list for each of our data combinations (generated above; 'spb_other', 'smb_ih', 'ih', 'ouachita_little', 'ouachita', 'little'). Each batch list will contain a separate line of code to run a single replicate at an a priori determined number of populations (<i>K</i>, listed in the chunk above for each dataset). We will run each analysis in 10 replicates at each <i>K</i>, e.g.:

structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_1
structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_2
structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_3
structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_4
structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_5
.
.
.
structure -K 1 -m mainparams -e extraparams -i structure_input.txt -o structure_output_1_10
structure -K 2 -m mainparams -e extraparams -i structure_input.txt -o structure_output_2_1
structure -K 2 -m mainparams -e extraparams -i structure_input.txt -o structure_output_2_2
.
.
.
where, in the output name, the first number represents the K value for the run, and the last number represents the replicate.

#### 1e.1. Generate batch list file; run the Rmd chunk below.
The Rmd chunk below generates a list of commands that contains the full cluster paths (/home/data/...) for necessary files.

##### Generate batch commands: `batch_cmd_lists/cih_structure_batch_cmd_list.txt`
```{r}
# N(pops) = 18

nk <- data.frame(c(1:18))
nreps <- data.frame(c(1:10))

cat("", file="batch_cmd_lists/cih_structure_batch_cmd_list.txt")

# Run loop to create file for storing commands
for(ii in 1:nrow(nk)) {

  for(aa in 1:nrow(nreps)) {
    
    structure_call <- paste("structure ")

    param_files <- paste(" -m /home/jcg5g9/data/SNOLH_Genomics/structure_analysis/data/structure_data/param_files/mainparams_ih -e /home/jcg5g9/data/SNOLH_Genomics/structure_analysis/data/structure_data/param_files/extraparams")

    input <- paste(" -i /home/jcg5g9/data/SNOLH_Genomics/structure_analysis/data/structure_data/input_data/cih_structure.txt")
  
    output <- paste(" -o /home/jcg5g9/data/SNOLH_Genomics/structure_analysis/data/structure_data/output_data/cih_structure_output/")
  
    cat(paste(structure_call, "-K ", nk[ii,], param_files, input, output,
            strsplit("cih_structure.txt", "_structure.txt", fixed=TRUE)[[1]][1], "_", nk[ii,], "_", nreps[aa,], sep=""),
      "\n", 
      file=paste("batch_cmd_lists/cih_structure_batch_cmd_list.txt"), # name file to store list
      append=TRUE)
  }
  
}
```

#### 1e.2. Generate shell script; run the Rmd chunk below.

##### IMPORTANT NOTE: This shell script was generated on the server directly, and thus the Rmd chunk below does not need to be run to generate the file. This is purely to keep a record of each script file. 

##### Generate batch commands: `shell_scripts/cih_structure.sh`
```{r}
#!/bin/bash
#-------------------------------------------------------------------------------
#  SBATCH CONFIG
#-------------------------------------------------------------------------------
## resources
#SBATCH --partition Lewis
#SBATCH --nodes=1
#SBATCH --ntasks=1  # used for MP#SBATCH -e error_%A_%a.err # Standard errorI codes, otherwise leav$
##SBATCH --cpus-per-task=12  # cores per task
#SBATCH --mem-per-cpu=16G  # memory per core (default is 1GB/core)
#SBATCH --time 2-00:00  # days-hours:minutes
#SBATCH --qos=normal
#SBATCH --array=23-220

## labels and outputs
#SBATCH --job-name=snolh_structure_jgunn
#
#SBATCH -o test_%A_%a.out # Standard output
#SBATCH -e error_%A_%a.err # Standard error

## notifications
#SBATCH --mail-user=jcg5g9@mail.missouri.edu  # email address for notifications
#SBATCH --mail-type=END,FAIL  # which type of notifications to send
#-------------------------------------------------------------------------------

#echo "### Starting at: $(date) ###"


# load packages
#module load rss/rss-2020
#module load structure/structure-2.3.4

#COMMANDA=`head -n ${SLURM_ARRAY_TASK_ID} ../batch_cmd_lists/cih_structure_batch_cmd_list.txt | tail -n 1`
#eval $COMMANDA


#echo "### Ending at: $(date) ###"
```

#### 1f: Prepare mainparam and extraparam files for STRUCTURE.
In this step, we are preparing the mainparam and extraparam input files for STRUCTURE so that they are unique to each analysis we are running.

##### 1f.1. Edit base mainparam STRUCTURE file (downloaded with STRUCTURE program) and generate a separate, unique mainparam file.

<b>mainparam file:</b> <br>
`../data/structure_data/param_files/mainparams_cih` <br> 

###### 1f.1.1. Edit "maxpops" value to reflect the number of populations designated in Step 3b above. These values should be the following:

<b>Populations:</b> 18 <br>

###### 1.f.1.2. Set the number of burn-in and MCMC iterations to run; these are the same for each analysis:

<b>Burn-in runs:</b> 500,000 <br>
<b>MCMC runs:</b> 1,000,000 <br>

###### 1f.1.3. Set the number of individuals. These values should be the following:

<b>Individuals:</b> 396 <br>

###### 1f.1.4. Set the number of loci. These values should be the following:

<b>Loci:</b> 138 <br>

###### 1f.1.5. Set 'ONEROWPERIND' to '0'

###### 1f.1.6. Set 'LABEL' to '1'

###### 1f.1.7. Set 'POPDATA' to '1'

###### 1f.1.8. Set 'POPFLAG' to '0'

##### 1f.2. Edit base extraparam STRUCTURE file (downloaded with STRUCTURE program).
We did not change any of the default settings in the extraparams file (most importantly, we used the default admixture model), so we only used a single extraparams file.

<b>extraparam file:</b> <br>
`../data/structure_data/param_files/extraparams` <br> 

### STEP 2: population Structure Analysis

#### 2a: Run STRUCTURE analysis using the input data generated in STEP 1. Navigate to `shell_scripts/` Be sure that all relative and full paths to all input files and output destination directories are set up properly (ideally, this is already done within this GitHub repo). This command line code assumes capability to run the code using SLURM or a SLURM-like cluster scheduling software.

Run `sbatch cih_structure.sh`

#### 2b: Structure output files are generated and stored here: `../data/structure_data/output_data/`.

#### 2c: Compress output directory into a zip file compatible with Structure Selector (Li and Liu 2017) or Structure Harvester (Earl and vonHoldt 2011) online.

#### 2d: Submit zip directory to Structure Selector or Structure Harvester to extract summary results

#### 2e: Copy detlaK table (Evanno et al. 2005) and save as excel file here: `../data/structure_data/summary_data`

#### 2f: Copy puechmaille table (Puechmaille et al. 2016) and save as excel file here:
`../data/structure_data/summary_data`
We found that Puechmaille metrics universally support K=8, and we graph the results for deltak and Puechmaille in Step 2g.5.

#### 2g: Visualize STRUCTURE runs for all data combinations.

##### 2g.1. Convert STRUCTURE files into aligned Q files compatible with analysis in the program CLUMPP (Jakobbson and Rosenberg 2007); run the rmd chunk below.

##### Convert STRUCTURE files to aligned Q files for CLUMPP: 
```{r}
# Get a list of structure files for each data combination
cih_sfiles <- list.files("../data/structure_data/output_data/cih_structure_output/", full.names = T)

# Extract q value information (ancestry proportions) from each run for each K value for each individual from the STRUCTURE output files in the directories listed above
cih_Q <- readQ(cih_sfiles)

# Tabulate information from the q lists
cih_tab <- tabulateQ(cih_Q)

# Summarize information from tabultions above
cih_summary <- summariseQ(cih_tab)

# Extract deltaK and associated summary information using Evanno method
cih_evanno <- evannoMethodStructure(cih_summary, returnplot = F) 

# Set infinity and NA to zero arbitrarily
cih_evanno$deltaK[cih_evanno$deltaK == "Inf"] <- 0
cih_evanno$deltaK[is.na(cih_evanno$deltaK)] <- 0

# Write Evanno table to Excel table for manuscript preparation.

## Convert to data frame
cih_evanno <- as.data.frame(cih_evanno)

## Write Excel file
write_xlsx(cih_evanno, "../data/structure_data/deltak_data/cih_deltak.xlsx")

# Align replicate runs for each K to correct label switching
cih_align <- alignK(cih_Q)
```

##### 2g.2. Export CLUMPP compatbile files for CLUMPP analysis; run the rmd chunk below to export CLUMPP associated files for each K.

<b>We used the following parameters: </b> <br>

Large-K-Greedy algorithm (paramrep = 3) <br>
10000 replicates <br>

### IMPORTANT NOTE: This step only needs to be run ONCE to generate files for CLUMPP. Once you have run this chunk, move on to Step 2g.3. Uncomment each line to run this code.

##### Export CLUMPP files:
```{r}
clumppExport(cih_align, 
            parammode = 3,
            paramrep = 10000, 
            exportpath = "../data/structure_data/clumpp_data/cih_clumpp")
```

The code above generates a .txt file (pop_K#-combined.txt) with combined cluster ancestry proportions for each individual at each K and stores it in a separate directory labeled "pop_K#", where '#' is the corresponding K value. Additionally, the code generates an accompanying "paramfile" that is input for CLUMPP, which contains information on parameters to generate merged datasets across our 10 replicates at each K.

##### 2g.3. Generate merged Q files using CLUMPP.
In this step, we used the software program CLUMPP (Jakobbson and Rosenberg 2007) to merge cluster ancestry proportion inferences for all replicate runs of each K across individuals. We downloaded the Linux 64-bit build of CLUMPP v.1.1.2 and installed it on our computing cluster. We then executed the program for each analysis by sequentially copying the associated paramfiles generated in the clumppExport function (see section above) to the CLUMPP home directory. All output files were then moved to the corresponding structure directory.

###### 2g.3.1. Downolad CLUMPP and install on cluster; navigate to the desired directory: `code`. Run the command: `wget https://rosenberglab.stanford.edu/software/CLUMPP_Linux64.1.1.2.tar.gz`

###### 2g.3.2. Run the command: `gunzip CLUMPP_Linux64.1.1.2.tar.gz`

###### 2g.3.3. Run the command: `tar -xvf CLUMPP_Linux64.1.1.2.tar`

###### 2g.3.4. For each analysis separately, copy the 'pop_K#-combined.txt' file and 'paramfile' over to the CLUMPP directory (`CLUMPP_Linux64.1.1.2`)

###### 2g.3.5. For each analysis separately, execute CLUMPP on the paramfile; run the code `./CLUMPP paramfile`
We are running this code with GREEDY OPTION 2, which uses random sampling of replicate runs. 

This code generates three additional files, which we moved back to the corresponding pop_K folder in the clumpp_data directory:

<b>Files generated: </b> <br>

pop_K#-combined-miscfile.txt <br>
pop_K#-combined-merged.txt <br>
pop_K#-combined-aligned.txt <br>

##### 2g.4. Plot deltaK results; run the rmd chunk below.

##### deltak results for all CIH populations: `04_cih_deltak.pdf`
```{r}
# DeltaK results
pdf("../figures/structure_figures/deltak_plots/04_cih_deltaK.pdf", width=8, height=5)

ggplot(cih_evanno, aes(x=k, y=deltaK)) +
  geom_point() + 
  geom_line() +
  theme_cowplot(theme_set(12)) +
  geom_vline(xintercept = 3, color = "blue") +
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 15)) +
  theme(axis.title.x = element_text(face = "italic")) +
  labs(x = "K", y = "delta K") + 
  scale_x_continuous("K", labels = as.character(cih_evanno$k), breaks = cih_evanno$k)

dev.off()
```

We found strongest support for K=3 using the deltaK metric. We found universal support for K=8 using the Puechmaille metric. We therefore present result for K=3 and K=8 in Step 2g.5 below. Results for deltaK and Puechmaille metrics are given in Tables S5 and S6, respectively.

##### 2g.5. Plot STRUCTURE runs at best K value (K=3 and K=8) for each analysis; run the rmd chunk below.

##### STRUCTURE results for CIH populations: 1) `04_cih_k3.pdf` and 2) `04_cih_k8.pdf`
```{r}
# Read in combined-merged Q table from CLUMPP
cih_k3 <- readQ("../data/structure_data/clumpp_data/cih_clumpp/pop_K3/pop_K3-combined-merged.txt")

# Visualize Structure
plotQ(cih_k3,
      grplab = cih[,c(13,7)],
      showindlab = FALSE, 
      ordergrp = F,
      selgrp = "River",
      showgrplab = T,
      showlegend = F, 
      showsp = F, 
      showdiv = T, 
      divsize = 2, 
      divtype = 1,
      divcol = "black",  
      grplabsize = 4, 
      grplabangle = 45,
      grplabjust = 0.5,
      legendkeysize = 15, 
      linealpha = 0,
      legendtextsize = 10, 
      linesize = 0.05, 
      pointsize = 4, 
      barbordercolour = "black",
      barbordersize = 0.1, 
      clustercol = c("#7570B3","#E7298A","#E6AB02"),
      exportplot = T,
      imgtype = "pdf",
      height = 10, 
      width = 100,
      outputfilename = "04_cih_k3",
      exportpath = "../figures/structure_figures/q_plots")

# Read in combined-merged Q table from CLUMPP
cih_k8 <- readQ("../data/structure_data/clumpp_data/cih_clumpp/pop_K8/pop_K8-combined-merged.txt")

# Visualize Structure
plotQ(cih_k8,
      grplab = cih[,c(13,7)],
      showindlab = FALSE, 
      ordergrp = F,
      selgrp = "River",
      showgrplab = T,
      showlegend = F, 
      showsp = F, 
      showdiv = T, 
      divsize = 2, 
      divtype = 1,
      divcol = "black",  
      grplabsize = 4, 
      grplabangle = 45,
      grplabjust = 0.5,
      legendkeysize = 15, 
      linealpha = 0,
      legendtextsize = 10, 
      linesize = 0.05, 
      pointsize = 4, 
      barbordercolour = "black",
      barbordersize = 0.1, 
      clustercol = c("#E6AB02", "#66A61E", "#A6761D", "#7570B3", "#D95F02", "#2166AC", "#E7298A", "#666666"),
      exportplot = T,
      imgtype = "pdf",
      height = 10, 
      width = 100,
      outputfilename = "04_cih_k8",
      exportpath = "../figures/structure_figures/q_plots")
```
These figures are the bases for Figures 3c and S2c, and for Figures 3d and S4, respectively, in the manuscript.
### STEP 3: Hybridization analysis with NEWHYBRIDS

See `snolh_structure_analysis.Rmd` (Line 190 - 201) for programs needed for analysis.

#### 3a: Convert genepop file to NEWHYBRIDS format and generate 'individual file' for analysis.

##### 3a.1. Parse the genepop dataset for CIH species into three pairwise comparison datasets before running NEWHYBRIDS analysis
Since we detected 3 optimal populations (K=3; one population representing the NB, one representing the LRB, and one representing the OB) in STRUCTURE analysis for the CIH populations, we first need to parse the dataset into three pairwise comparisons of each of these three groups: 

  1) NB and LRB 
  2) NB and OB
  3) LRB and OB 
  
This is due to the fact that NEWHYBRIDS analysis assumes two major "parent" populations and determines hybrid category from genotype frequencies within "offspring" individuals based on these two parent groupings. The above comparisons will allow us to detect hybrids specifically between NB and LRB, between NB and OB, and between LRB and OB. 

To parse the dataset, we manually altered the IH genepop Excel file (`../data/genepop_data/cih_genepop.xlsx`) to include only the individuals for each pairwise analysis, and we saved the associated Excel and .txt files:

  1) `../data/genepop_data/nb_lrb_genepop.xlsx` and `../data/genepop_data/nb_lrb_genepop.txt`
  2) `../data/genepop_data/nb_ob_genepop.xlsx` and `../data/genepop_data/nb_ob_genepop.txt`
  3) `../data/genepop_data/lrb_ob_genepop.xlsx` and `../data/genepop_data/lrb_ob_genepop.txt`

##### 3a.2. Generate metadata files that can be used to make individual files for NEWHYBRIDS; Run the Rmd chunk below.

##### Generate metadatafiles for three pairwise groups:
```{r}
# metadata for NB and LRB
nb_lrb_metadata <- cih_metadata %>%
  filter(Putative_Taxon != "Ouachita_OuachitaRiver")

# metadata for NB and OB
nb_ob_metadata <- cih_metadata %>%
  filter(Putative_Taxon != "Ouachita_LittleRiver")

# metadata for LRB and OB
lrb_ob_metadata <- cih_metadata %>%
  filter(Putative_Taxon != "Neosho") 
```

##### 3a.3. Generate input files for NEWHYBRIDS; Run the Rmd chunk below:

Running the Rmd chunk below generates 6 files: 
  1) NewHybrids input for NB and LRB (`nb_lrb_nh.txt`),
  2) accompanying individual file for NB and LRB (`nb_lrb_individuals.txt`)
  3) NewHybrids input for NB and OB (`nb_ob_nh.txt`),
  4) accompanying individual file for NB and OB (`nb_ob_individuals.txt`)
  5) NewHybrids input for LRB and OB (`lrb_ob_nh.txt`),
  6) accompanying individual file for Little River VBassand OB (`lrb_ob_individuals.txt`)
    
These files are stored here: `../data/newhybrids_data/input_data/`

##### Generate NEWHYBRIDS input file and accompanying individual file:
```{r}
# Generate newhybrids files for NB and LRB
genepop_newhybrids("../data/genepop_data/nb_lrb_genepop.txt", 
                   path = "../data/newhybrids_data/input_data/nb_lrb_nh.txt")

# Generate newhybrids files for NB and OB
genepop_newhybrids("../data/genepop_data/nb_ob_genepop.txt", 
                   path = "../data/newhybrids_data/input_data/nb_ob_nh.txt")

# Generate newhybrids files for LRB and OB
genepop_newhybrids("../data/genepop_data/lrb_ob_genepop.txt", 
                   path = "../data/newhybrids_data/input_data/lrb_ob_nh.txt")

# Generate individual file (list of sample names ('Structure_Num') to accompany NewHybrids for NB and LRB)
nb_lrb_individuals <- data.frame(indiv = as.character(nb_lrb_metadata$Structure_Num))

# Generate individual file (list of sample names ('Structure_Num') to accompany NewHybrids for NB and OB)
nb_ob_individuals <- data.frame(indiv = as.character(nb_ob_metadata$Structure_Num))

# Generate individual file (list of sample names ('Structure_Num') to accompany NewHybrids for LRB and OB)
lrb_ob_individuals <- data.frame(indiv = as.character(lrb_ob_metadata$Structure_Num))

# Write individual files to .txt format
write_tsv(nb_lrb_individuals, "../data/newhybrids_data/input_data/nb_lrb_individuals.txt")
write_tsv(nb_ob_individuals, "../data/newhybrids_data/input_data/nb_ob_individuals.txt")
write_tsv(lrb_ob_individuals, "../data/newhybrids_data/input_data/lrb_ob_individuals.txt")
```

#### 3b: Install newhybrids on local machine (or plan to use a remote server, setting up paths as needed)
NewHybrids was installed on a local machine here: `/Users/joegunn/Downloads/newhybrids/`

##### 3b.1. Set the number of burn-in and MCMC iterations to run:

<b>Burn-in runs:</b> 100,000 <br>
<b>MCMC runs:</b> 500,000 <br>

#### 3c: Run parallelnewhybrids for MAC; run the Rmd chunk below to run the parallel newhybrids program on the input data.
This code should be run independently for each of the three data comparisons listed above. Before moving on to the next comparison, all input and output data should be moved to the `../data/newhybrids_data/output_data` directory. Then move on with the next comparison.

##### Run NewHybrids program with 100,000 burn-in and 500,000 MCMC sweeps
```{r}
parallelnh_OSX("../data/newhybrids_data/input_data/", 
               where.NH = "/Users/joegunn/Downloads/newhybrids/", 
               burnin = 100000, 
               sweeps = 500000)
```

The parallelnewhybrids program will generate results and store them in a new directory (`NH.Results`) within the same directory as the input data. Since we are running multiple sequential analyses, we chose to rename the resulting output directory and store the input data within that directory along with the associated results so as not to confuse which input files go with which analyses. See specific steps below.

##### 3c.1. Manually rename output directory: `nb_lrb_output/`, `nb_ob_output/`, `lrb_ob_output/`

##### 3c.2. Manually move all output and input files into the newly named directory.

##### 3c.3. Move output folders into the `output_data/` directory within `newhybrids_data/`.

#### 3d: Visualize NEWHYBRIDS results; run the Rmd chunk below to read in, clean, and plot NewHybrids output.

##### Visualize NEWHYBRIDS output and generate plots for all comparisons: `nb_lrb.pdf`, `nb_ob.pdf`, `lrb_ob.pdf`
```{r}
# Read in NewHybrids "PofZ" output txt file for Neosho and LRB
nb_lrb_pofz <- read_tsv("../data/newhybrids_data/output_data/nb_lrb_output/nb_lrb_nh.txt_PofZ.txt")

# Read in NewHybrids "PofZ" output txt file for Neosho and OB
nb_ob_pofz <- read_tsv("../data/newhybrids_data/output_data/nb_ob_output/nb_ob_nh.txt_PofZ.txt")

# Read in NewHybrids "PofZ" output txt file for Little River and OB
lrb_ob_pofz <- read_tsv("../data/newhybrids_data/output_data/lrb_ob_output/lrb_ob_nh.txt_PofZ.txt")

# Omit first two columns (the first column is individual number and the second is empty)
nb_lrb_pofz <- data.frame(nb_lrb_pofz[,-c(1:2)])
nb_ob_pofz <- data.frame(nb_ob_pofz[,-c(1:2)])
lrb_ob_pofz <- data.frame(lrb_ob_pofz[,-c(1:2)])

# Change column names to indicate hybrid class clearly for Neosho and LRB
colnames(nb_lrb_pofz) <- c("pure_nb","pure_lrb","f1","f2","bc_nb","bc_lrb")

# Change column names to indicate hybrid class clearly for Neosho and Ouachita River Bass
colnames(nb_ob_pofz) <- c("pure_nb","pure_ob","f1","f2","bc_nb","bc_ob")

# Change column names to indicate hybrid class clearly for Little River and Ouachita River Bass
colnames(lrb_ob_pofz) <- c("pure_lrb","pure_ob","f1","f2","bc_lrb","bc_ob")

# Bind metadata to NewHybrids output to match posterior probabilities with individual samples
nb_lrb_pofz <- cbind(nb_lrb_metadata, nb_lrb_pofz)
nb_ob_pofz <- cbind(nb_ob_metadata, nb_ob_pofz)
lrb_ob_pofz <- cbind(lrb_ob_metadata, lrb_ob_pofz)


# Gather dataset for plotting and convert variables to factors/characters. 'Structure_Num' was converted to a character in this step, and then factor levels were set in the next step to ensure that individuals were graphed in the same order as in STRUCTURE (for later direct one-to-one comparison)
nb_lrb_pofz <- nb_lrb_pofz %>%
  gather(c(14:19), key = "hybrid_category", value = "probability") %>%
  mutate(hybrid_category = factor(hybrid_category)) %>%
  mutate(Structure_Num = as.character(Structure_Num))

nb_ob_pofz <- nb_ob_pofz %>%
  gather(c(14:19), key = "hybrid_category", value = "probability") %>%
  mutate(hybrid_category = factor(hybrid_category)) %>%
  mutate(Structure_Num = as.character(Structure_Num))

lrb_ob_pofz <- lrb_ob_pofz %>%
  gather(c(14:19), key = "hybrid_category", value = "probability") %>%
  mutate(hybrid_category = factor(hybrid_category)) %>%
  mutate(Structure_Num = as.character(Structure_Num))

# Change levels to get the correct order (see explanation for step above)
nb_lrb_pofz$River <- factor(nb_lrb_pofz$River, levels = c("Honey_Creek", "Spavinaw_Creek", "Baron_Fork", "Caney_Creek", "Lee_Creek", "Blackfork_Creek", "Honobia_Creek", "Little_River", "Glover_River", "Big_Eagle_Creek", "Upper_Mountain_Fork", "Mountain_Fork", "Pero_Creek_Rolling_Fork_trib", "Cossatot_River_AR", "Western_Saline_River_AR", "Little_Missouri_River_AR", "Caddo_River_AR", "Ouachita_River_AR", "Eastern_Saline_River_AR"))

nb_ob_pofz$River <- factor(nb_ob_pofz$River, levels = c("Honey_Creek", "Spavinaw_Creek", "Baron_Fork", "Caney_Creek", "Lee_Creek", "Blackfork_Creek", "Honobia_Creek", "Little_River", "Glover_River", "Big_Eagle_Creek", "Upper_Mountain_Fork", "Mountain_Fork", "Pero_Creek_Rolling_Fork_trib", "Cossatot_River_AR", "Western_Saline_River_AR", "Little_Missouri_River_AR", "Caddo_River_AR", "Ouachita_River_AR", "Eastern_Saline_River_AR"))

lrb_ob_pofz$River <- factor(lrb_ob_pofz$River, levels = c("Honey_Creek", "Spavinaw_Creek", "Baron_Fork", "Caney_Creek", "Lee_Creek", "Blackfork_Creek", "Honobia_Creek", "Little_River", "Glover_River", "Big_Eagle_Creek", "Upper_Mountain_Fork", "Mountain_Fork", "Pero_Creek_Rolling_Fork_trib", "Cossatot_River_AR", "Western_Saline_River_AR", "Little_Missouri_River_AR", "Caddo_River_AR", "Ouachita_River_AR", "Eastern_Saline_River_AR"))

# Convert analysis order column to factor
nb_lrb_pofz <- nb_lrb_pofz %>%
  mutate(Analysis_order_W2E_U2D_corrected = factor(Analysis_order_W2E_U2D_corrected))

nb_ob_pofz <- nb_ob_pofz %>%
  mutate(Analysis_order_W2E_U2D_corrected = factor(Analysis_order_W2E_U2D_corrected))

lrb_ob_pofz <- lrb_ob_pofz %>%
  mutate(Analysis_order_W2E_U2D_corrected = factor(Analysis_order_W2E_U2D_corrected))

# Reorder analysis order to be in the same order as Rivers (same as presented in Structure q plot)
nb_lrb_pofz <- nb_lrb_pofz %>% 
  mutate(Analysis_order_W2E_U2D_corrected = fct_reorder(Analysis_order_W2E_U2D_corrected, as.integer(River)))

nb_ob_pofz <- nb_ob_pofz %>% 
  mutate(Analysis_order_W2E_U2D_corrected = fct_reorder(Analysis_order_W2E_U2D_corrected, as.integer(River)))

lrb_ob_pofz <- lrb_ob_pofz %>% 
  mutate(Analysis_order_W2E_U2D_corrected = fct_reorder(Analysis_order_W2E_U2D_corrected, as.integer(River)))

# Save dataframes for future use in introgress analysis (Analysis 3)
save(nb_lrb_pofz, file = "../data/newhybrids_data/output_data/nb_lrb_output/nb_lrb_pofz.rda")
save(nb_ob_pofz, file = "../data/newhybrids_data/output_data/nb_ob_output/nb_ob_pofz.rda")
save(lrb_ob_pofz, file = "../data/newhybrids_data/output_data/lrb_ob_output/lrb_ob_pofz.rda")

# Plot posterior probability of assignment to each hybrid category as a cumulative bar plot for each individual (colors represent assignment probabilities for each of six possible hybrid categories)
pdf("../figures/newhybrids_figures/04_nb_lrb.pdf", width=120, height=12)

ggplot(nb_lrb_pofz, aes(x = Analysis_order_W2E_U2D_corrected, y = probability, fill = hybrid_category)) + 
   geom_bar(stat = "identity", color = "black", show.legend = T,  color = "black") +
   geom_hline(yintercept = 0.5, color = "red", linetype = "longdash", size = 3) +
   theme_set(theme_cowplot(12)) +
   labs(x = "Individual", y = "Cumulative probability of hybrid ID") +
   scale_fill_manual(values = c("blue","red","green","yellow","white","white")) +
   theme(axis.title.x = element_blank())  +
   theme(panel.border = element_rect(colour = "black", fill=NA, size=1)) +
   theme(axis.text = element_text(angle = 90)) +
   scale_y_continuous(expand=c(0,0))

dev.off()


pdf("../figures/newhybrids_figures/04_nb_ob.pdf", width=120, height=12)

ggplot(nb_ob_pofz, aes(x = Analysis_order_W2E_U2D_corrected, y = probability, fill = hybrid_category)) + 
   geom_bar(stat = "identity", color = "black", show.legend = T, color = "black") +
   geom_hline(yintercept = 0.5, color = "red", linetype = "longdash", size = 3) +
   theme_set(theme_cowplot(12)) +
   labs(x = "Individual", y = "Cumulative probability of hybrid ID") +
   scale_fill_manual(values = c("blue","red","green","yellow","white","white")) +
   theme(axis.title.x = element_blank())  +
   theme(panel.border = element_rect(colour = "black", fill=NA, size=1)) +
   theme(axis.text = element_text(angle = 90)) +
   scale_y_continuous(expand=c(0,0))

dev.off()

pdf("../figures/newhybrids_figures/04_lrb_ob.pdf", width=120, height=12)

ggplot(lrb_ob_pofz, aes(x = Analysis_order_W2E_U2D_corrected, y = probability, fill = hybrid_category)) + 
   geom_bar(stat = "identity", color = "black", show.legend = T, color = "black") +
   geom_hline(yintercept = 0.5, color = "red", linetype = "longdash", size = 3) +
   theme_set(theme_cowplot(12)) +
   labs(x = "Individual", y = "Cumulative probability of hybrid ID") +
   scale_fill_manual(values = c("blue","red","green","yellow","white","white")) +
   theme(axis.title.x = element_blank())  +
   theme(panel.border = element_rect(colour = "black", fill=NA, size=1)) +
   theme(axis.text = element_text(angle = 90)) +
   scale_y_continuous(expand=c(0,0))

dev.off()
```
These figures are the bases for Figure S2c in the manuscript.

#### 3e: Identify individuals of hybrid status (non-pure, F1, F2, or backcross generation hybrids) across the whole dataset for each comparison
We are designating individuals as hybrid status if the posterior probability of assignment to any of the four hybrid categories (F1, F2, Backross to Parent 1, Backross to Parent 2) is greater than 0.50. We are basing this threshold on Long et al. (2021), who performed an in-depth power analysis following the hybriddetective workflow (Wringe et al. 2017) for each hybrid category at various numbers of SNP loci for varying posterior probability cutoffs. They found that the highest power to accurately detect hybrid individuals (and avoid type 2 error, failure to reject the null hypothesis when it is false) occurs at a probability cutoff of 0.5.

##### 3e.1. Generate a list of hybrid individual sample names to be removed from subsequent datasets and save as an .Rda.

##### Generate and save list of hybrid individuals
```{r}
# Summarize all hybrids together by population for Neosho and LRB
nb_lrb_hybrid_summary <- nb_lrb_pofz %>%
  filter(probability > 0.5) %>%
  group_by(River, hybrid_category) %>%
  count()

# Summarize all hybrids together by population for Neosho and OB
nb_ob_hybrid_summary <- nb_ob_pofz %>%
  filter(probability > 0.5) %>%
  group_by(River, hybrid_category) %>%
  count()

# Summarize all hybrids together by population for Little River and OB 
lrb_ob_hybrid_summary <- lrb_ob_pofz %>%
  filter(probability > 0.5) %>%
  group_by(River, hybrid_category) %>%
  count()

# There is a single Backcross to Little River in the Ouachita range (Western Saline River)
```

## ------------------------ END OF PHASE 4 OF STRUCTURE AND HYBRID ASSIGNMENT ANALYSIS ----------------------- ##

## ------------------------ END OF ANALYSIS 2: STRUCTURE AND HYBRID ASSIGNMENT ANALYSIS ----------------------- ##

